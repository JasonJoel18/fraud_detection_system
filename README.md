# ğŸ§  Uncertainty-Aware Deep Learning for Early Detection of Alzheimer's Disease Using MRI Image Data

## ğŸ“– Overview
This project leverages advanced deep learning techniques with uncertainty estimation to aid in the early detection of Alzheimer's disease using MRI data. It includes a full pipeline from data preprocessing to deployment, with a user-friendly web interface for practical use. Designed for both research and clinical applications.

---

## âœ¨ Features
- **ğŸ”„ Advanced Data Processing**
  - Robust preprocessing pipeline for MRI images.
  - Support for both full datasets and test subsets.
  - Automated workflows for seamless data preparation.

- **ğŸ¤– Machine Learning Model**
  - State-of-the-art uncertainty estimation.
  - Comprehensive training and evaluation pipelines.
  - Prediction with confidence scores.

- **ğŸ“Š Visualization Tools**
  - Uncertainty visualization for better interpretability.
  - Publication-quality figure generation.
  - Interactive, web-based visualizations.

- **ğŸŒ Web Interface**
  - Built using Flask for simplicity and speed.
  - Intuitive prediction and visualization tools.
  - Real-time uncertainty analysis.

## Project Structure

    â”œâ”€â”€ data              <- Main dataset directory containing MRI images
    â”‚   â””â”€â”€ external      <- Data from Kaggle sources
    â”‚
    â”œâ”€â”€ data2             <- Subset of data for testing with smaller dataset
    â”‚
    â”œâ”€â”€ docs              <- Documentation and research outputs
    â”‚   â”œâ”€â”€ figures       <- Generated graphics and figures
    â”‚   â”‚   â”œâ”€â”€ fig1.png
    â”‚   â”‚   â”œâ”€â”€ fig2.jpeg
    â”‚   â”‚   â””â”€â”€ ... (visualization outputs)
    â”‚   â”œâ”€â”€ base_model    <- Kaggle notebook outputs for baseline model
    â”‚   â”œâ”€â”€ proposed_model<- Kaggle notebook outputs for proposed model
    â”‚   â”œâ”€â”€ AlzheimerPrediction.tex
    â”‚   â””â”€â”€ wordcount.log
    â”‚
    â”œâ”€â”€ models            <- Trained and serialized models
    â”‚   â””â”€â”€ .gitkeep
    â”‚
    â”œâ”€â”€ references        <- Reference materials
    â”‚   â””â”€â”€ folder_structure.txt
    â”‚
    â”œâ”€â”€ reports           <- Generated analysis reports
    â”‚
    â”œâ”€â”€ src               <- Source code
    â”‚   â”œâ”€â”€ data          <- Scripts for dataset preparation
    â”‚   â”‚   â””â”€â”€ make_dataset.py
    â”‚   â”œâ”€â”€ models        <- Model training and prediction scripts
    â”‚   â”‚   â”œâ”€â”€ predict_model.py
    â”‚   â”‚   â””â”€â”€ train_model.py
    â”‚   â”œâ”€â”€ visualization <- Visualization scripts
    â”‚   â”‚   â”œâ”€â”€ visualize.py           <- Results visualization with uncertainty
    â”‚   â”‚   â””â”€â”€ visualize_for_paper.py <- Thesis paper figure generation
    â”‚   â”œâ”€â”€ scripts       <- Web application files
    â”‚   â”‚   â””â”€â”€ app.py    <- Flask web application
    â”‚   â”œâ”€â”€ static        <- Static files for web app (CSS, output images)
    â”‚   â””â”€â”€ index.html    <- Web application interface
    â”‚
    â”œâ”€â”€ README.md         <- Project documentation
    â”œâ”€â”€ environment2.yml  <- Environment configuration
    â””â”€â”€ alzheimerPrediction.code-workspace

## Installation

1. Clone the repository
```bash
git clone [repository-url]
cd [repository-name]
```

2. Create a virtual environment (recommended)
- On Mac/Linux:
```bash
python -m venv venv
```
- On Windowsx:
```bash
source venv/bin/activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

## Usage

### Data Preparation

```bash
python src/data/make_dataset.py
```

### Model Training
```bash
python src/models/train_model.py
```

### Model Prediction
```bash
python src/models/predict_model.py
```

### Visualization
```bash
python src/visualization/visualize.py`
```
### Web Application
```bash
python scripts/app.py`
```

Then navigate to `http://localhost:5000` in your web browser.

## Development and Testing

- Use the `data2` directory for testing with a smaller dataset
- Run tests before submitting any changes
- Follow the existing code style and documentation patterns

## Documentation

- Detailed documentation is available in the `docs` directory
- LaTeX files contain comprehensive methodology and results
- Kaggle notebook outputs are stored in `docs/base_model` and `docs/proposed_model`

## Contributing

1. Fork the repository
2. Create a new branch (`git checkout -b feature/improvement`)
3. Make your changes
4. Run tests
5. Commit your changes (`git commit -am 'Add new feature'`)
6. Push to the branch (`git push origin feature/improvement`)
7. Create a Pull Request

## Contact

jasonjoel188@gmail.com

## Acknowledgments

- [Cookie Cutter Data Science](https://drivendata.github.io/cookiecutter-data-science/) for project structure inspiration.
